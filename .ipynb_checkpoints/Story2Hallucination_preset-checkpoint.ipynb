{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hElmF-malqM"
   },
   "source": [
    "## Restart after running this cell!\n",
    "\n",
    "You must run this cell and then restart and rerun everything for the PyTorch version to be correct. Otherwise the model will run but not produce any meaningful output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c33IJYCRafX0"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-905f480faee9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mCUDA_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"nvcc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"--version\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"UTF-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\", \"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"release\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CUDA version:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCUDA_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0m\u001b[0;32m    425\u001b[0m                **kwargs).stdout\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stderr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    949\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1418\u001b[0m             \u001b[1;31m# Start the process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1421\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m                                          \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
    "print(\"CUDA version:\", CUDA_version)\n",
    "\n",
    "if CUDA_version == \"10.0\":\n",
    "    torch_version_suffix = \"+cu100\"\n",
    "elif CUDA_version == \"10.1\":\n",
    "    torch_version_suffix = \"+cu101\"\n",
    "elif CUDA_version == \"10.2\":\n",
    "    torch_version_suffix = \"\"\n",
    "else:\n",
    "    torch_version_suffix = \"+cu110\"\n",
    "\n",
    "! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzl4Zrd7SEvG"
   },
   "source": [
    "Install Big Sleep from pip. (Note that the latest major upgrade to 0.5.x breaks this script. I'm working on a fix to make it compatible soon.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2jUsCZXaqcw"
   },
   "outputs": [],
   "source": [
    "!pip install big-sleep==0.4.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "El_t0JgjSIye"
   },
   "source": [
    "Mount your Google Drive. You will need a folder called story_halluc in drive to store the images there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjQaqenajK83"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m99xCwxSSRwt"
   },
   "source": [
    "This block takes the text and generates the images.  Update the all_text variable to change the story. You can adjust the parameters to change how many images are run before changing phrases and when to restart with a fresh image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfJ0RMCAauV3"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import string\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "\n",
    "from big_sleep import Imagine\n",
    "from big_sleep.clip import tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from skimage.measure import compare_ssim\n",
    "\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageFont, ImageDraw\n",
    "\n",
    "TEXT = 'story_hallucinator' \n",
    "SAVE_EVERY = 1\n",
    "SAVE_PROGRESS = True\n",
    "LEARNING_RATE = 0.1\n",
    "ITERATIONS =  1\n",
    "\n",
    "def train_step(self, epoch, i, rand=0):\n",
    "  total_loss = 0\n",
    "\n",
    "  for _ in range(self.gradient_accumulate_every):\n",
    "      losses = self.model(self.encoded_text) \n",
    "      loss = (sum(losses) / self.gradient_accumulate_every) + rand*np.random.randn()\n",
    "      total_loss += loss\n",
    "      loss.backward()\n",
    "\n",
    "  self.optimizer.step()\n",
    "  self.optimizer.zero_grad()\n",
    "\n",
    "  if (i + 1) % self.save_every == 0:\n",
    "      with torch.no_grad():\n",
    "          # best = torch.topk(losses[2], k = 1, largest = False)[1]\n",
    "          mres = self.model.model()\n",
    "          image = mres[len(mres)-1].cpu()\n",
    "          num = i // self.save_every\n",
    "          save_image(image, Path(f'./{self.textpath}.{num}.png'))\n",
    "\n",
    "model = Imagine(\n",
    "    text = TEXT,\n",
    "    save_every = SAVE_EVERY,\n",
    "    lr = LEARNING_RATE,\n",
    "    iterations = ITERATIONS,\n",
    "    save_progress = SAVE_PROGRESS\n",
    ")\n",
    "filename = TEXT.replace(' ', '_')\n",
    "\n",
    "\n",
    "burnin=20 #\n",
    "checkin_gap = 10\n",
    "long_sim_gap = 10\n",
    "span = 6\n",
    "iterations = 100\n",
    "display_gap = 50\n",
    "similarity = 0.9\n",
    "\n",
    "all_text_list = [\"The moon has a face like the clock in the hall,\",\n",
    "                 \"She shines on thieves on the garden wall,\",\n",
    "                 \"On streets and fields and harbour quays,\",\n",
    "                 \"And birdies asleep in the forks of the trees,\"]\n",
    "\n",
    "iter_num = 0\n",
    "last_one = 0\n",
    "rand = 0\n",
    "model.text = \" \".join(words[:span])\n",
    "model.encoded_text = tokenize(model.text).cuda()\n",
    "for j in range(burnin):\n",
    "    train_step(model, 0, 0, rand)\n",
    "for epoch in range(0, len(all_text_list)):\n",
    "    restart_point = iter_num\n",
    "    i = 0\n",
    "    while i < iterations:\n",
    "        phrase =all_text_list[epoch]\n",
    "        model.text = phrase.translate(str.maketrans('', '', string.punctuation))\n",
    "        model.encoded_text = tokenize(model.text).cuda()\n",
    "        train_step(model, epoch, iter_num, rand)\n",
    "        \n",
    "        if iter_num % display_gap == 0:\n",
    "          print(f'iter: {iter_num} text={phrase}')\n",
    "          image_cur = Image(f'./{filename}.{iter_num}.png')\n",
    "          display(image_cur)\n",
    "        \n",
    "        if i % checkin_gap == 0 and i > 0:\n",
    "          imageA = cv2.imread(f'./{filename}.{iter_num}.png')\n",
    "          imageB = cv2.imread(f'./{filename}.{restart_point}.png')\n",
    "          # convert the images to grayscale\n",
    "          grayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\n",
    "          grayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n",
    "          (score, diff) = compare_ssim(grayA, grayB, full=True)\n",
    "          toinc = checkin_gap\n",
    "          print(f'iter{iter_num}: rand={rand} sim={score} smooth={grayB.std()}, ext={((grayB < 50) | (grayB > 205)).mean()}')\n",
    "          if score>similarity or grayB.std()<15 or ((grayB < 50) | (grayB > 205)).mean()>0.9:\n",
    "              print(f'restart!')\n",
    "              model = Imagine(\n",
    "                  text = TEXT,\n",
    "                  save_every = SAVE_EVERY,\n",
    "                  lr = LEARNING_RATE,\n",
    "                  iterations = ITERATIONS,\n",
    "                  save_progress = SAVE_PROGRESS\n",
    "              )\n",
    "              model.text = \" \".join(words[epoch:epoch+span]).translate(str.maketrans('', '', string.punctuation))\n",
    "              model.encoded_text = tokenize(model.text).cuda()\n",
    "              for j in range(burnin):\n",
    "                train_step(model, epoch, iter_num, rand) \n",
    "              iter_num = restart_point\n",
    "              i = 0\n",
    "              rand = 0\n",
    "              continue\n",
    "        i += 1\n",
    "        iter_num += 1\n",
    "        \n",
    "        \n",
    "    for i in range(last_one,iter_num):\n",
    "      msg_orig =all_text_list[epoch]\n",
    "      img = PIL.Image.open(f'./{filename}.{i}.png')\n",
    "      W, H = img.size\n",
    "      draw = ImageDraw.Draw(img)\n",
    "      font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf\", 18)\n",
    "      msgs = [msg_orig]\n",
    "      w, h = draw.textsize(msg_orig, font=font)\n",
    "      if w>W:\n",
    "        split = span // 2\n",
    "        msgs = [\" \".join(words[epoch:epoch+split]), \" \".join(words[epoch+split:epoch+span])]\n",
    "      for shift, msg in enumerate(msgs): \n",
    "        w, h = draw.textsize(msg, font=font)\n",
    "        x, y = (W-w)/2, 7*(H-h)/8 + shift*h\n",
    "        adj = 1\n",
    "        #move right\n",
    "        shadowColor = \"black\"\n",
    "        draw.text((x-adj, y), msg, fill=shadowColor, font=font)\n",
    "        #move left\n",
    "        draw.text((x+adj, y), msg, fill=shadowColor, font=font)\n",
    "        #move up\n",
    "        draw.text((x, y+adj), msg, fill=shadowColor, font=font)\n",
    "        #move down\n",
    "        draw.text((x, y-adj), msg, fill=shadowColor, font=font)\n",
    "        #diagnal left up\n",
    "        draw.text((x-adj, y+adj), msg, fill=shadowColor, font=font)\n",
    "        #diagnal right up\n",
    "        draw.text((x+adj, y+adj), msg, fill=shadowColor, font=font)\n",
    "        #diagnal left down\n",
    "        draw.text((x-adj, y-adj), msg, fill=shadowColor, font=font)\n",
    "        #diagnal right down\n",
    "        draw.text((x+adj, y-adj), msg, fill=shadowColor, font=font)\n",
    "        draw.text((x, y), msg, fill=\"white\", font=font)\n",
    "      img.save(f'./{filename}.{i}.png')\n",
    "    last_one = iter_num\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e922of2WR3tB"
   },
   "source": [
    "This section zips your image files and stores the zip file in a folder called story_halluc on your google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGpSuIxjFSps"
   },
   "outputs": [],
   "source": [
    "!zip s2h.zip *.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWfYQ7yvE6qr"
   },
   "outputs": [],
   "source": [
    "!cp s2h.zip /content/drive/MyDrive/story_halluc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcNMH32_TPe7"
   },
   "source": [
    "Next download the zip file from Drive, unzip it in a folder and run the following:\n",
    "\n",
    "```\n",
    "ffmpeg -framerate 10 -i story_hallucinator.%d.png -c:v libx264 -crf 0 story_hallucination.mp4\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6TgvSSQN3zS"
   },
   "outputs": [],
   "source": [
    "!rm story_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIg29_14jwNx"
   },
   "outputs": [],
   "source": [
    "!rm s2h.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVuvkIWJnjWY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Story2Hallucination_preset.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
